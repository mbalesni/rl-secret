{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd09639334d58e3ed79494cd2f9eacfe6489aca6192a226943ad57e365354ecee17",
   "display_name": "Python 3.8.0 64-bit ('rl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from trajectories import TrajectoriesDataset, preprocess_dataset, find_activations\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "time.sleep(30)\n",
    "os.system('touch ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 128\n",
    "data_path = 'trajectories/ep15000_dur36.20_ret0.52/trajectories/10.00K.pt'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "dataset = torch.load(data_path)\n",
    "trigger_activations = find_activations(dataset.observations, dataset.actions, target='trigger').to(device)\n",
    "trigger_activations_indices = torch.argmax(trigger_activations, axis=-1).to(device) # indices of steps when action to take the trigger was taken \n",
    "prize_activations = find_activations(dataset.observations, dataset.actions, target='prize')\n",
    "prize_activations_indices = torch.argmax(prize_activations, axis=-1) # indices of steps when action to take the prize was taken \n",
    "episodes_with_prize_mask = torch.sum(prize_activations, axis=-1).to(device) # mask for episodes where prizes were taken\n",
    "episodes_with_trigger_mask = torch.sum(trigger_activations, axis=-1).to(device)  # (N, )\n",
    "\n",
    "train_loader, valid_loader = preprocess_dataset(dataset, data_path, sum_rewards=True, normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([0, 1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([0, 1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from reward_predictor import RewardPredictor\n",
    "from train_reward_predictor import PAD_VAL, ACTION_SPACE_SIZE, OBSERVATION_SPACE_DIMS\n",
    "\n",
    "model_path = 'trajectories/ep10000_dur47.70_ret-0.02/reward-prediction/model_r1.000_p1.000_a0.879_l0.065.pt'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(model_path).to(device)\n",
    "# model = RewardPredictor(OBSERVATION_SPACE_DIMS, ACTION_SPACE_SIZE, device, verbose=False).to(device)\n",
    "\n",
    "ATTENTION_THRESHOLD = 0.2\n",
    "\n",
    "seq_len = dataset.observations.shape[1]\n",
    "attention_weights_global = torch.zeros((batch_size, seq_len*2+1), device=device) # N, S*2\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    observations, actions, returns, indices = batch\n",
    "\n",
    "    N, _, _ = actions.shape\n",
    "\n",
    "    trigger_activations_batch = trigger_activations[indices] # credit assignment ground truth\n",
    "    trigger_activations_indices_batch = trigger_activations_indices[indices]\n",
    "    prize_activations_batch = prize_activations_indices[indices] # moments at which we want to evaluate attention\n",
    "    prize_episodes_mask_batch = episodes_with_prize_mask[indices] # mask to zero out attention in episodes without touching prize\n",
    "    trigger_episodes_mask_batch = episodes_with_trigger_mask[indices]\n",
    "\n",
    "    # print('triggers', torch.argmax(trigger_activations_batch, axis=-1).shape)\n",
    "    # print('episodes mask:', episodes_with_prize_mask_batch.shape)\n",
    "\n",
    "    observations = observations.transpose(\n",
    "                    2, 4).transpose(0, 1).to(device)\n",
    "    actions = actions.transpose(0, 1).to(device)\n",
    "    returns = returns.transpose(0, 1).to(device)\n",
    "\n",
    "    _, attention_matrices = model(observations, actions, output_attention=True) # (N, L, S) where `L` - reward sequence, `S` - inputs sequence\n",
    "\n",
    "    # for some weird reason, attention_matrices[:, prize_activations_batch] results in [N, N, S] rather than [N, S]\n",
    "    # fixed with help of: https://discuss.pytorch.org/t/selecting-element-on-dimension-from-list-of-indexes/36319/2?u=nick-baliesnyi\n",
    "    attention_vals = attention_matrices[torch.arange(N), prize_activations_batch]\n",
    "    attention_vals *= prize_episodes_mask_batch[:, None] # zero out episodes where prize wasn't touched\n",
    "\n",
    "    \n",
    "    attention_discrete = torch.gt(attention_vals, ATTENTION_THRESHOLD, out=torch.empty(attention_vals.shape, dtype=torch.uint8, device=device))\n",
    "\n",
    "    attention_indices = torch.arange(0, seq_len) + seq_len\n",
    "    attention_indices = attention_indices.repeat(batch_size, 1).to(device)\n",
    "    print('att indices', attention_indices.device)\n",
    "    attention_indices -= trigger_activations_indices_batch[:, None]\n",
    "\n",
    "    added_values = torch.zeros_like(attention_weights_global)\n",
    "    attention_weights_global += added_values.scatter(1, attention_indices, attention_vals)\n",
    "\n",
    "    print('attention_discrete', attention_discrete.shape)\n",
    "    print('ground truth', trigger_activations_batch[episode])\n",
    "    print('credit assignment', attention_discrete[episode])\n",
    "\n",
    "    # TODO: padding mask\n",
    "    true_positives = torch.sum(torch.logical_and(attention_discrete, trigger_activations_batch))\n",
    "    precision = true_positives / torch.sum(attention_discrete)\n",
    "    n_relevant_episodes = torch.sum(torch.logical_and(prize_episodes_mask_batch, trigger_episodes_mask_batch))\n",
    "    recall = true_positives / n_relevant_episodes\n",
    "\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "\n",
    "    # weights_averaged = torch.sum(attention_weights_global, axis=0) / n_relevant_episodes\n",
    "    # x_axis = torch.arange(weights_averaged.shape[0]) - seq_len\n",
    "    # plt.plot(x_axis.cpu(), weights_averaged.cpu())\n",
    "    # print(weights_averaged)\n",
    "    episode = 3\n",
    "\n",
    "    weights = attention_vals[episode]\n",
    "    x_axis = torch.arange(weights.shape[0]).to(device) - trigger_activations_indices_batch[episode].to(device)\n",
    "    plt.plot(x_axis.cpu(), weights.cpu())\n",
    "    print(weights)\n",
    "\n",
    "    # if log:\n",
    "    #    weights_averaged = torch.sum(attention_weights_global, axis=0) / batch_size # / log_frequency\n",
    "    #    attention_weights_global *= 0\n",
    "    #    x_axis = torch.arange(weights_averaged.shape[0]) - seq_len\n",
    "    #    plt.plot(x_axis.cpu(), weights_averaged.cpu())\n",
    "    #    wandb.log('chart', plt)\n",
    "\n",
    "    # episode = 3\n",
    "    # attn = attention_at_prize_activations[episode].detach().cpu().numpy()\n",
    "    # plt.plot(attn)\n",
    "\n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unique: tensor([1, 2])\nred tensor([255,  76,  76], dtype=torch.uint8)\npink tensor([255,  76, 249], dtype=torch.uint8)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-31T18:12:11.314750</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p4f674c8b5a)\">\n    <image height=\"218\" id=\"imagefd1df0af2b\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAC8UlEQVR4nO3cwW3CQBBAUTtKG1BH6IHaoBCu9AB1QCFOCU4k823Be+cVOxL6mgvLOAzDNAAv9bX2APAJhAYBoUFAaBAQGgSEBgGhQUBoEPhee4B38fMzf+Z2e/0c/3E4zJ+5318/xyew0SAgNAgIDQJCg4DQICA0CAgNAkKDwDh4YZ15PObP7HbL3PV8zp/Z75e5i3k2GgSEBgGhQUBoEBAaBIQGAaFBQGgQ8MI6dD7Nnzmdu7vo2GgQEBoEhAYBoUFAaBAQGgSEBgGhQcAL642ZFvo2xnGZz2EZNhoEhAYBoUFAaBAQGgSEBgGhQUBoEPDCemNOXka/JRsNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJ+GbIxl8vaE/AKNhoEhAYBoUFAaBAQGgSEBgGhQUBoEPDf+xCw0SAgNAgIDQJCg4DQICA0CAgNAkKDgBfWfzAdj2uPsGnj9br2CJtno0FAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoExmEYprWHgHdno0FAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAaBXxbZGX71ngGvAAAAAElFTkSuQmCC\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mbd5629f46e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.455\" xlink:href=\"#mbd5629f46e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(28.27375 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.755\" xlink:href=\"#mbd5629f46e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(73.57375 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"122.055\" xlink:href=\"#mbd5629f46e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(115.6925 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.355\" xlink:href=\"#mbd5629f46e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(160.9925 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.655\" xlink:href=\"#mbd5629f46e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(206.2925 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m519d80feb0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m519d80feb0\" y=\"11.73\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 15.529219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m519d80feb0\" y=\"57.03\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 60.829219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m519d80feb0\" y=\"102.33\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 106.129219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m519d80feb0\" y=\"147.63\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 151.429219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m519d80feb0\" y=\"192.93\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 196.729219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p4f674c8b5a\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# debug\n",
    "loader = DataLoader(dataset_new, batch_size=128)\n",
    "episode = 3\n",
    "\n",
    "for i, batch in enumerate(loader):\n",
    "    observations, actions, reward, indices = batch\n",
    "\n",
    "    # observations = observations.type(torch.FloatTensor)\n",
    "    # observations[observations == 10] = 0\n",
    "\n",
    "    # mean = torch.mean(observations, axis=(0,1,2,3))\n",
    "    # std = torch.std(observations, axis=(0,1,2,3))\n",
    "    # observations = (observations - mean) / std\n",
    "\n",
    "    returns = torch.ones_like(reward) * 0\n",
    "    sums = torch.sum(reward, axis=1)\n",
    "\n",
    "    returns += sums[:, None]\n",
    "    returns += 1\n",
    "    print('unique:', torch.unique(returns))\n",
    "    renormalized = (observations * std + mean).type(torch.ByteTensor)\n",
    "    plt.imshow(renormalized[episode, 3, :, :, :])\n",
    "    print('red',renormalized[episode, 3, 12, 12, :])\n",
    "    print('pink',renormalized[episode, 7, 12, 12, :])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}